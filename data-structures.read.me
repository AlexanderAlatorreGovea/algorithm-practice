Data structures are a way to organize an manipulate data.
Relationships between data values to perform operations.
A data structure is the collection of data values, the relationship among them,
and the functions and operations we apply on the data.

Complexity analysis. When a solution is better is because it has
a better analysis. 
Time Complexity: how fast an algorithm runs.
Space Complexity: measure of how much memory or space an algo takes up
One solution may have a better time Complexity and a worse space Complexity.

Memory: 
When you write code you create variables and behind the scenes a variable has to be stored.
So to think of "memory" you can image it as a canvas that lives in your computer and is divided into slots.
In this canvas there is a finite number of memory slots. 
When you declare a variable, your program will store the number one in a memory slot.
So that memory slot is not free anymore. Your program will always store memory in a slot that is free.
So we store variables and information in back to back memory slots.
Memory is composed of bits (0101), so when you store data in a memory slot, you store them in a bit.
The conjunction of 8 bits is called a byte. So the number one is transformed in a binary number.
So the number one could be represented in a binary like 0000 0001.
So with one byte you do not have many combinations. So you can increase the number of bits to store more info.

Integers whether we represent them with 62 bits or less, the key thing to remember, we are dealing with fixed width integers.
So you know that a 32 bit integer, it will only take up 4 memory slots (8*4). This implies that the number of memory slots is always a constant.

Strings are mapped to an integer like 65 which is transformed into a bits of binary.

At a memory slot you can store a pointer to a memory slot. So instead of pointing to an address, you are not storing extra memory.
So with pointers you can jump across memory slots.


Big 0 Notation:
The algos are affected by the sizes of the array.
Time Complexity: measure of an algorithm speed as the size of the input increases.

0(1) or constant: Complexity means that as the size of the input increases, the speed remains constant. 
    This picks up only a value in a memory slot.
    Additions and multiplications are constant times.
0(n) or linear time Complexity: as the size increases the speed of the algorithm increases linearly

0(n^2): 0 of n*n 

3 sample algorithms 
a = [..., 1000]
B1(a) => 1 + a[0] // has an 0(1) Complexity (constant speed). You are only grabing one spot in memory.
B2(a) => sum(a)  // 0(n), this is linear because we would go through all elements once
B3(a) => pair(a) // retraverse through the array multiple times 

0(1) // you just did a bunch of addition or other operations for example
0(log(n)) 
0(n) //traverse through the array once from left to right and once from right through left
0(nlog(n))
0(n^2), // two nested algorithms
0(n^3), 
0(n^4)


Trees:

A tree is a graph which has a top node or root node (10 is the root node).
Every root has a child node. The child nodes cannot point back to the root or any nodes above. 
Each node in the tree does not get to have two parents. The tree cannot be disconnected and 
be called a tree. A binary tree has two child nodes. A ternary tree is when the root has 3 child nodes.
Some trees can point back to the parent nodes.

Space time Complexity is 0(n)s time Complexity, o(n)t time Complexity.
When you go down every single binary tree, you are going to get 0(log(n)).
When you eliminate have of the tree you get complexity of 0(log(N)) T.

If you have have inbalance tree, you may not have a 0(log(N)).

Any path in a tree that starts at the root is a branch, the bottom nodes are leaves, every level 
are levels and a tree is complete if every level is filled up. If the final level has nodes.